{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9815e4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add paths\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../experiments')\n",
    "\n",
    "# Import modules\n",
    "from run_experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f903eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key already configured\n",
      "‚úÖ LLaMA API key already configured\n",
      "‚úÖ DeepSeek API key already configured\n",
      "\n",
      "üí° If all set, you can run experiments with any configured APIs!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# üîê API Keys Setup - Set your API keys here (optional if already configured)\n",
    "# =============================================================================\n",
    "\n",
    "# Set your API keys here (leave empty if already configured in .env or environment)\n",
    "OPENAI_API_KEY = ''    # Your OpenAI API key\n",
    "LLAMA_API_KEY = ''     # Your LLaMA API key  \n",
    "DEEPSEEK_API_KEY = ''  # Your DeepSeek API key\n",
    "\n",
    "# Apply the keys to environment variables (only if not already set)\n",
    "import os\n",
    "\n",
    "# Check and set OpenAI key\n",
    "if OPENAI_API_KEY:\n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "    print(\"‚úÖ OpenAI API key set from notebook\")\n",
    "elif os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚úÖ OpenAI API key already configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  OpenAI API key not available\")\n",
    "\n",
    "# Check and set LLaMA key\n",
    "if LLAMA_API_KEY:\n",
    "    os.environ['LLAMA_API_KEY'] = LLAMA_API_KEY\n",
    "    print(\"‚úÖ LLaMA API key set from notebook\")\n",
    "elif os.getenv('LLAMA_API_KEY'):\n",
    "    print(\"‚úÖ LLaMA API key already configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  LLaMA API key not available\")\n",
    "\n",
    "# Check and set DeepSeek key\n",
    "if DEEPSEEK_API_KEY:\n",
    "    os.environ['DEEPSEEK_API_KEY'] = DEEPSEEK_API_KEY\n",
    "    print(\"‚úÖ DeepSeek API key set from notebook\")\n",
    "elif os.getenv('DEEPSEEK_API_KEY'):\n",
    "    print(\"‚úÖ DeepSeek API key already configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  DeepSeek API key not available\")\n",
    "\n",
    "print(\"\\nüí° If all set, you can run experiments with any configured APIs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5553e",
   "metadata": {},
   "source": [
    "### 1.1 Evaluation Against Ground Truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e1cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:run_experiments:Running experiment with gpt-4o-mini using few_shot_prompt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.1 Evaluation Against Ground Truth Experiment:\n",
      " Loading data from: ../data/sample_data/sample_posts_test.csv\n",
      " Loaded 5 posts\n",
      " Using columns: PostID='PostId', Content='Body', Label='Expert_Label'\n",
      " Label distribution: {'Neutral': 3, 'Positive': 2}\n",
      "\n",
      " Running experiment: gpt-4o-mini_few_shot_prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:11<00:00,  2.40s/it]\n",
      "INFO:run_experiments:Running experiment with gpt-4o-mini using zero_shot_prompt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to: ../results/custom_experiments/gpt-4o-mini_few_shot_prompt_predictions.csv\n",
      " Accuracy: 1.000, F1: 1.000, Response Rate: 1.000\n",
      "\n",
      " Running experiment: gpt-4o-mini_zero_shot_prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.30it/s]\n",
      "INFO:run_experiments:Running experiment with gpt-4o-mini using naive_prompt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to: ../results/custom_experiments/gpt-4o-mini_zero_shot_prompt_predictions.csv\n",
      " Accuracy: 1.000, F1: 1.000, Response Rate: 1.000\n",
      "\n",
      " Running experiment: gpt-4o-mini_naive_prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to: ../results/custom_experiments/gpt-4o-mini_naive_prompt_predictions.csv\n",
      " Accuracy: 1.000, F1: 1.000, Response Rate: 1.000\n",
      "\n",
      " Generating comparison summary...\n",
      " Comparison summary saved to: ../results/custom_experiments/comparison_summary.csv\n",
      "\n",
      " Results Summary:\n",
      "                  Experiment  Accuracy  F1_Macro  Response_Rate\n",
      " gpt-4o-mini_few_shot_prompt       1.0       1.0            1.0\n",
      "gpt-4o-mini_zero_shot_prompt       1.0       1.0            1.0\n",
      "    gpt-4o-mini_naive_prompt       1.0       1.0            1.0\n",
      "\n",
      " Experiment completed! Results saved to: ../results/custom_experiments/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 1.1 Evaluation Against Ground Truth Experiment:\")\n",
    "\n",
    "results = run_experiment_with_custom_data(\n",
    "    data_path=\"../data/sample_data/sample_posts_test.csv\",\n",
    "    models=[\"gpt-4o-mini\"],  \n",
    "    post_id_col=\"PostId\",\n",
    "    content_col=\"Body\", \n",
    "    expert_label_col=\"Expert_Label\",\n",
    "    prompt_templates=[\"few_shot_prompt\",\"zero_shot_prompt\", \"naive_prompt\"], \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f50a61f",
   "metadata": {},
   "source": [
    "### 1.2 Pure Prediction Mode (No ground truth needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b40602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pure Prediction Mode:\n",
      " Loading data from: ../data/sample_data/sample_posts_test.csv\n",
      " Loaded 5 posts for prediction\n",
      " Using columns: PostID='PostId', Content='Body'\n",
      " Predicting sentiment using prompt: few_shot_prompt\n",
      "\n",
      " Predicting with gpt-4o-mini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gpt-4o-mini: 5/5 predictions (100.0% success rate)\n",
      " Distribution: {'Neutral': 3, 'Positive': 2}\n",
      "\n",
      " Predicting with deepseek-chat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with deepseek-chat: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:21<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deepseek-chat: 5/5 predictions (100.0% success rate)\n",
      " Distribution: {'Neutral': 3, 'Positive': 2}\n",
      "\n",
      " Predictions saved to: ../results/predictions/sentiment_predictions_20250730_161256.csv\n",
      " Results summary:\n",
      "   - Total posts: 5\n",
      "   - Models used: ['gpt-4o-mini', 'deepseek-chat']\n",
      "   - New columns: ['Predicted_gpt-4o-mini', 'Predicted_deepseek-chat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Pure Prediction Mode:\")\n",
    "\n",
    "# Original prediction function unchanged\n",
    "prediction_results = predict_sentiment_batch(\n",
    "    data_path=\"../data/sample_data/sample_posts_test.csv\",\n",
    "    models=[\"gpt-4o-mini\", \"deepseek-chat\"],\n",
    "    post_id_col=\"PostId\",\n",
    "    content_col=\"Body\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c54d1278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample Prediction Results:\n",
      "üÜî POST_001:\n",
      "   GPT-4o-mini: Positive\n",
      "   deepseek-chat: Positive\n",
      "üìù I thought I'd need help last night, but I managed to calm my breathing down....\n",
      "\n",
      "üÜî POST_018:\n",
      "   GPT-4o-mini: Neutral\n",
      "   deepseek-chat: Neutral\n",
      "üìù The research shows mixed results for this treatment approach....\n",
      "\n",
      "üÜî POST_016:\n",
      "   GPT-4o-mini: Neutral\n",
      "   deepseek-chat: Neutral\n",
      "üìù Has anyone tried the new inhaler device? Wondering about side effects....\n",
      "\n",
      " Sentiment distribution:\n",
      "GPT-4o-mini:\n",
      "Predicted_gpt-4o-mini\n",
      "Neutral     3\n",
      "Positive    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "deepseek-chat:\n",
      "Predicted_deepseek-chat\n",
      "Neutral     3\n",
      "Positive    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display sample results\n",
    "print(\"\\n Sample Prediction Results:\")\n",
    "sample_cols = ['PostId', 'Body', 'Predicted_gpt-4o-mini', 'Predicted_deepseek-chat']\n",
    "for _, row in prediction_results[sample_cols].head(3).iterrows():\n",
    "    print(f\"üÜî {row['PostId']}:\")\n",
    "    print(f\"   GPT-4o-mini: {row['Predicted_gpt-4o-mini']}\")\n",
    "    print(f\"   deepseek-chat: {row['Predicted_deepseek-chat']}\")\n",
    "    print(f\"üìù {row['Body'][:80]}...\")\n",
    "    print()\n",
    "\n",
    "# Create sentiment mapping for analysis\n",
    "sentiment_map = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "prediction_results['Sentiment_GPT_4o_mini'] = prediction_results['Predicted_gpt-4o-mini'].map(sentiment_map)\n",
    "prediction_results['Sentiment_deepseek-chat'] = prediction_results['Predicted_deepseek-chat'].map(sentiment_map)\n",
    "\n",
    "print(f\" Sentiment distribution:\")\n",
    "print(\"GPT-4o-mini:\")\n",
    "print(prediction_results['Predicted_gpt-4o-mini'].value_counts())\n",
    "print(\"\\ndeepseek-chat:\")\n",
    "print(prediction_results['Predicted_deepseek-chat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511af93",
   "metadata": {},
   "source": [
    "### 2.1 Evaluation Against Ground Truth with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6876d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:run_experiments:Running confidence experiment with gpt-4o-mini using zero_shot\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading data from: ../data/sample_data/sample_posts_test.csv\n",
      " Loaded 5 posts\n",
      "\n",
      " Running confidence experiment: gpt-4o-mini_zero_shot_confidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.37it/s]\n",
      "INFO:run_experiments:Running confidence experiment with gpt-4o-mini using naive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to: results/confidence_experiments/gpt-4o-mini_zero_shot_confidence_predictions.csv\n",
      " Accuracy: 1.000, Mean Confidence: 0.760\n",
      "\n",
      " Running confidence experiment: gpt-4o-mini_naive_confidence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to: results/confidence_experiments/gpt-4o-mini_naive_confidence_predictions.csv\n",
      " Accuracy: 1.000, Mean Confidence: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Using new confidence functionality\n",
    "confidence_results = run_experiment_with_confidence(\n",
    "    data_path=\"../data/sample_data/sample_posts_test.csv\",\n",
    "    models=[\"gpt-4o-mini\"],\n",
    "    post_id_col=\"PostId\",\n",
    "    content_col=\"Body\",\n",
    "    expert_label_col=\"Expert_Label\",\n",
    "    prompt_templates=[\"zero_shot\", \"naive\"],  # base template names\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30eff2",
   "metadata": {},
   "source": [
    "### 2.2 Pure Prediction Mode - with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d2970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:run_experiments:Running confidence experiment with gpt-4o-mini using naive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading data from: ../data/sample_data/sample_posts_test.csv\n",
      " Loaded 5 posts for confidence prediction\n",
      " Using columns: PostID='PostId', Content='Body'\n",
      " Predicting sentiment with confidence using template: naive\n",
      "\n",
      " Predicting with confidence using gpt-4o-mini...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing posts with gpt-4o-mini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gpt-4o-mini: 5/5 predictions (100.0% success rate)\n",
      " Mean confidence: 0.740\n",
      " Distribution: {'Neutral': 3, 'Positive': 2}\n",
      "\n",
      " Confidence predictions saved to: ../results/predictions/confidence_predictions_20250730_161322.csv\n",
      " Results summary:\n",
      "   - Total posts: 5\n",
      "   - Models used: ['gpt-4o-mini']\n",
      "   - New columns: ['Predicted_gpt-4o-mini', 'Confidence_gpt-4o-mini']\n",
      " Confidence prediction completed\n",
      " Prediction result shape: (5, 6)\n",
      "\n",
      " Sample Results:\n",
      " POST_001: Positive (conf: 0.800)\n",
      " POST_018: Neutral (conf: 0.700)\n",
      " POST_016: Neutral (conf: 0.700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "confidence_prediction_results = predict_sentiment_batch_with_confidence(\n",
    "    data_path=\"../data/sample_data/sample_posts_test.csv\",\n",
    "    models=[\"gpt-4o-mini\"],\n",
    "    post_id_col=\"PostId\",\n",
    "    content_col=\"Body\",\n",
    "    prompt_template=\"naive\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\" Confidence prediction completed\")\n",
    "print(f\" Prediction result shape: {confidence_prediction_results.shape}\")\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\n Sample Results:\")\n",
    "display_cols = ['PostId', 'Predicted_gpt-4o-mini', 'Confidence_gpt-4o-mini']\n",
    "for _, row in confidence_prediction_results[display_cols].head(3).iterrows():\n",
    "    print(f\" {row['PostId']}: {row['Predicted_gpt-4o-mini']} (conf: {row['Confidence_gpt-4o-mini']:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e89de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment mapping for analysis\n",
    "sentiment_map = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "confidence_prediction_results['Sentiment_GPT_4o_mini'] = confidence_prediction_results['Predicted_gpt-4o-mini'].map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80ca111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>Body</th>\n",
       "      <th>Expert_Label</th>\n",
       "      <th>Category</th>\n",
       "      <th>Predicted_gpt-4o-mini</th>\n",
       "      <th>Confidence_gpt-4o-mini</th>\n",
       "      <th>Sentiment_GPT_4o_mini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POST_001</td>\n",
       "      <td>I thought I'd need help last night, but I mana...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Health Improvement</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POST_018</td>\n",
       "      <td>The research shows mixed results for this trea...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Generated</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POST_016</td>\n",
       "      <td>Has anyone tried the new inhaler device? Wonde...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Generated</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POST_002</td>\n",
       "      <td>There was a fuss about the drug about ten year...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Uncertainty</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POST_009</td>\n",
       "      <td>The new inhaler technique really helped me dur...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Generated</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId                                               Body Expert_Label  \\\n",
       "0  POST_001  I thought I'd need help last night, but I mana...     Positive   \n",
       "1  POST_018  The research shows mixed results for this trea...      Neutral   \n",
       "2  POST_016  Has anyone tried the new inhaler device? Wonde...      Neutral   \n",
       "3  POST_002  There was a fuss about the drug about ten year...      Neutral   \n",
       "4  POST_009  The new inhaler technique really helped me dur...     Positive   \n",
       "\n",
       "             Category Predicted_gpt-4o-mini  Confidence_gpt-4o-mini  \\\n",
       "0  Health Improvement              Positive                     0.8   \n",
       "1           Generated               Neutral                     0.7   \n",
       "2           Generated               Neutral                     0.7   \n",
       "3         Uncertainty               Neutral                     0.6   \n",
       "4           Generated              Positive                     0.9   \n",
       "\n",
       "   Sentiment_GPT_4o_mini  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_prediction_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940dad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
